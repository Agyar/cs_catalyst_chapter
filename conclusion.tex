\section{Conclusion}
\label{sec:conclusion}

We have successfully integrated Catalyst into Code\_Saturne (a computational
fluid dynamics code developed at EDF R\&D). After testing the prototype in our
corporate supercomputer Ivanoe, we find Catalyst to be a relevant solution to
provide Code\_Saturne users with visualization coprocessing.  Catalyst proved to allow a
simple and fast implementation of an adaptor. We use D3 (a filter originally 
performing a redistribution of the data among MPI processes) as a ghost cell
handler. We feel that the code responsible for the ghost cells management in D3
could be integrated directly into ParaView/Catalyst since applying D3 can be
time consuming.  

Our preliminary results are based on a 51M and a 204M elements mesh, which is above the
average size case used by EDF engineers in our industrial environment.  We plan
to perform simulation on at least 400M elements meshes in the near future.  
We have also
performed simulation up to 300 nodes and are currently planning not using more
in this cluster. This is due to the typical simulation node size
being around 150 nodes for our engineers.  We also plan to work on another of
our corporate supercomputers, an IBM BG/Q with 65k cores. In that case, we will
test on a much bigger number of cores.  The increase of memory use found in the
results section indicates that memory optimizations are to be performed before
running on the IBM BG/Q. We did not in this study perform any delicate memory
tweaking in order to reduce the memory consumption. We are currently working on
this point, experimenting new VTK $in$-$situ$ data structures that may highly
reduce this overhead.

We are mostly satisfied with the integration of Catalyst in Code\_Saturne.
Our first version of our integration will be most probably released in September 
2013 as part of a new version of this open-source software. 

