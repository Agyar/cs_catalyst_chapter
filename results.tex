\section{Results}
\label{sec:results}

\subsection{Required User Interactions for Co-processing}
   
Before presenting our results we briefly describe how the user interactions were
performed. The following steps were necessary in order to use the developed
co-processing technology:

1) A ``light version'' of the input mesh is generated as explained in section~\ref{sec:pip_conf_tools}. 
As the user possesses a CAD version of the geometry that is parametrized, it is then possible to
obtain meshes at different spatial resolutions. A ``light mesh'' of small size in
memory and representative of the CAD geometry is obtained. Figure~\ref{fig:piece} represents
the ``light version'' of the mesh used in our experiments.

2) A short simulation (normally just a few seconds on a local machine) on the ``light mesh'' is run.
This simulation allows to define the information about the result fields needed to create a
visualisation pipeline in ParaView (e.g. temperature, pressure, velocity). An ``augmented light mesh''
is therefore created.

3) The mesh and the fields obtained at the end of step 2 are then read in ParaView
and the user defines her/his visualisation pipeline. At the end of this step
a simple click in the ParaView interface will create a Python file that
programmatically defines the visualisation operations to be performed
$in$-$situ$.

4) Finally the real simulation is ran using a full resolution size mesh. The
co-processing part of the simulation reads the python script containing the
definition of the visualisation pipeline. This step is expected to be
time-consuming.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[scale=0.195]{pictures/pieceofcake.eps}
    %\captionof{figure}{Original geometry for our use case}
    \captionof{figure}{}
    \label{fig:piece}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[scale=0.41]{pictures/res.eps}
    %\captionof{figure}{A final coprocessed picture of our simulation. The simulation was run with 128 layers.}
    %\captionof{figure}{A final coprocessed picture of our simulation.}
    \captionof{figure}{}
    \label{fig:res}
  \end{subfigure}
  \caption{(a) original geometry of our use case\\
  \hspace{8em}(b)  a final coprocessed picture of our simulation}
\end{figure}

\subsection{Use Cases}

Our simulations have been run on Ivanoe, an EDF corporate supercomputer,
composed of 1382 nodes, each node having 12 cores for a total of 16584 cores. In
these simulations we associate one MPI process by core and we use from 720 cores up
to 3600 cores. We include two use cases that were run on this supercomputer. The
choice of the cases is motivated by two main factors: the size of the mesh and
the complexity of the visualization pipeline. We detail next these two impacting factors.

1) Mesh size. We chose to use two meshes representing the same geometry but at
different resolutions, one made of 51M hexahedral elements and another of 204M
hexahedrals. In our industrial environment at EDF most simulation engineers use
meshes composed by less than 51M of element, that is why we chose this mesh size to be
representative of the work performed by an average engineer during his work routine.
Furthermore, a 51M elements mesh more than doubles the size used in the results
presented in~\cite{6092322} for the PHASTA adaptor. On the other hand, when research
oriented simulations are performed at EDF, these simulations currently contain around 200M
elements. We choose this size as a typical research oriented or ``heavy mesh'' simulation data.

2) Pipeline complexity. We define two pipelines aimed to be representative of two
different situations: users performing simple and light visualization
operations (e.g. generating slices in a volume) and another using very
time-consuming visualization tasks (e.g. performing volume rendering).

\begin{table}
\centering
\begin{tabular}{|p{1.5cm}|p{3.0cm}|p{2.70cm}|p{1.50cm}|}
\hline
\multicolumn{4}{|c|}{\textbf{USE CASES SUM UP}}\\
\hline
NAME & SIZE & PIPELINE & FIGURES \\
\hline
 %& & & \\
$CASE$\_$A$ & 51M hexahedrals, \newline industrial size case & \textbf{heavy}:
\newline volume rendering, \newline celldatatopointdata \newline and glyphs  &
5a 5c 5e\\
\hline
 %& & & \\
$CASE$\_$B$ & 204M hexahedrals, \newline research size case & \textbf{light}:
\newline 9 slices,\newline celldatatopointdata  & 5b 5d 5f   \\
\hline
\end{tabular}
%\vspace{-0.1in}
\caption{Description of our two use cases.}
\label{fig:tab}
%\end{figure}
\vspace{-0.15in}
\end{table}
In the following we name our uses cases:
$CASE$\_$A$, use case using an average mesh size of 51M hexahedrals and a
visualization pipeline including volume rendering which aims to be very time-consuming.
$CASE$\_$B$, our second use case, contains a light visualization pipeline simply
performing some slices but on a large mesh of 204M hexahedrals.

Table~\ref{fig:tab} summarizes the composition of these use cases. In all our use cases we
run a simulation consisting in a fluid with physical properties identical to
water passing through the mesh. Then the output is generated at each step, for a
total of 10 co-processed visualization images.

%\vspace{-0.10in}
\subsection{Results}

\begin{figure}
        \begin{subfigure}[b]{0.50\textwidth}
                \includegraphics[scale=0.50]{pictures/test41.ps}
                \caption{Time overhead of storage}
                \label{fig:over}
        \end{subfigure}
        ~
        \begin{subfigure}[b]{0.50\textwidth}
                \includegraphics[scale=0.50]{pictures/test42.ps}
                \caption{Time overhead of storage}
                \label{fig:204over}
        \end{subfigure}

        \begin{subfigure}[b]{0.50\textwidth}
          \includegraphics[scale=0.50]{pictures/test1.ps}
                \caption{Execution time with/out coprocessing}
                \label{fig:copro}
        \end{subfigure}%
        ~
        \begin{subfigure}[b]{0.50\textwidth}
          \includegraphics[scale=0.50]{pictures/test12.ps}
                \caption{Execution time with/out coprocessing}
                \label{fig:204copro}
        \end{subfigure}%

        \begin{subfigure}[b]{0.50\textwidth}
                \includegraphics[scale=0.50]{pictures/test2.ps}
                \caption{Execution time comparison with storage.}
                \label{fig:ensight}
        \end{subfigure}
        ~
        \begin{subfigure}[b]{0.50\textwidth}
                \includegraphics[scale=0.50]{pictures/test22.ps}
                \caption{Execution time comparison with storage.}
                \label{fig:204ensight}
        \end{subfigure}
        \caption{CASE\_A (left) and CASE\_B (right) results}\label{fig:animals}
\end{figure}

Figure~\ref{fig:res} presents an image obtained from one of our $in$-$situ$
simulations with $CASE$\_$A$.
We see the flux of water moving around the vertical cylinders, the glyphs being attached 
to the velocity vectorial field. The color of the volume rendering represents 
the turbulent viscosity of the fluid. 

We establish first the overhead induced by storing our simulation results in
figure~\ref{fig:over} and~\ref{fig:204over}. We observe an average of 18\% and
14\% of time used to store results, for $CASE$\_$A$ and $CASE$\_$B$
respectively. These figures correspond to the comparison of $T_w$ and $T_s +
T_w$ in equation~\ref{eq:first}. 
This overhead tends to increase with the number of processes in
use. One can also notice that the overhead is also not stable and subject 
to important variations with a peak at
26\%. We thus identify the storage process as a bottleneck in everyday CFD
studies for its average overhead and its high instability in execution time.

Figure~\ref{fig:copro} shows two graphs of $CASE$\_$A$: in red the execution 
time versus the number of cores, in blue the execution time without
the co-processing overload. These figures correspond to the comparison of $T_s$
and $T_s + T_{process}$ in equation~\ref{eq:second}.
We are satisfied by this overload that is comprised between 20 and 30\% of the total execution time, 
when we chose complicated task with a high $T_{process}$.
Moreover, it looks like this overload is decreasing when the number of cores increases. 
Figure~\ref{fig:204copro} shows the exact same behavior in the $CASE$\_$B$ experiment. Both
graphs are difficult to distinguish as the time needed for co-processing is
circumscribed between 6 and 10 seconds, the overload (the difference between $T_s$ and $T_s + T_{process}$) is less than one
percent of the total execution time. We notice that having heavy $T_{process}$ is not very usual in our applications and 
we consider $CASE$\_$A$ as an example of worst case scenario.

We also decided to compare the Catalyst overhead with a non-VTK-based 
storage strategy that performs no visualization operations. Figure~\ref{fig:ensight} and~\ref{fig:204ensight}, 
show the comparison of the global execution time with Catalyst co-processing
versus the Ensight Gold storage format. This means comparing $T_s + T_w$ 
and $T_s + T_{process} + T_{w-in-situ}$. Figure~\ref{fig:ensight} presents
our implementation results with $CASE$\_$A$. This compares positively for Catalyst as the overhead
is approximately 10\% and decreases when the number of cores increases. We
notice that for $CASE$\_$A$ the heavy $T_{process}$ is already taken into
account in the $in$-$situ$ curve but $T_r + T_v$ is still not performed for the
traditional visualisation scheme. This means that this result is very positive
and we should not forget that $T_r + T_v$ is very time consuming for this case
(and saturates our scientific PCs at EDF R\&D). 

Figure~\ref{fig:204ensight}
presents our results for $CASE$\_$B$. Here we can see the potential of Catalyst
when 
lighter and more relevant visualization tasks are processed. Indeed, there is no more 
overhead as we gain an average of 10\% of execution time while freeing
ourselves from storage issues (we evaluate the execution time peak of
3000 processes as a result of concurrent accesses on our 
supercomputer storage disks). To emphasize this, Table~\ref{fig:size_tab} shows how much data each
solution generates, namely a basic storage in Ensight Gold format versus our
co-processing implementation using Catalyst. These informations are those of our
CASE\_B when performing a 10 steps simulation. Both size are
expected to grow proportionally to the size of the mesh input, and the number of
steps. Therefore, we expect the gain provided by the use of co-processing 
to be increasingly interesting when moving forward in use case size.

\begin{table}[!h]
\centering
\begin{tabular}{|p{3.5cm}|p{3.5cm}|}
\hline
\multicolumn{2}{|c|}{\textbf{*PROCESSING SIZE COMPARISON}}\\
\hline
STORAGE & COPROCESSING \\
\hline 
 %& \\
57Gio & 1,3Mio \\
\hline 
\end{tabular} 
%\vspace{-0.1in}
\caption{CASE\_B comparison between the size of processed results and simple storage. The simulation was run on 10 steps, with 10
pictures co-processed.}
\label{fig:size_tab}
%\end{figure}
\end{table}

